# ğŸš€ QUICK START GUIDE - Python ML Backend Integration

## âœ… What's Been Created

### Python Backend (`python_backend/`)
- âœ… **FastAPI Server** - Complete REST API with WebSocket support
- âœ… **YOLOv8 Detection** - Cow/Buffalo detection (rejects other animals)
- âœ… **ByteTrack Tracking** - Unique ID assignment and counting
- âœ… **Milking Detection** - Udder analysis for lactation status
- âœ… **Lameness Detection** - Pose estimation and gait analysis
- âœ… **Supabase Integration** - Automatic database sync

### Flutter Services
- âœ… **PythonBackendService** - HTTP/WebSocket client
- âœ… **AIDetectionProvider** - State management for ML operations
- âœ… **Example Screen** - Ready-to-use UI implementation

## ğŸ¯ Setup in 5 Minutes

### 1. Backend Setup
```bash
cd python_backend
chmod +x setup.sh
./setup.sh
```

### 2. Configure Supabase
Edit `python_backend/.env`:
```env
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_anon_key
SUPABASE_SERVICE_KEY=your_service_key
```

### 3. Run Database Migration
Open Supabase SQL Editor and run:
```sql
-- See BACKEND_INTEGRATION_GUIDE.md section "Update Supabase Schema"
```

### 4. Start Backend
```bash
cd python_backend
./start.sh
```
Backend runs at: `http://localhost:8000`

### 5. Update Flutter Config
Edit `lib/services/python_backend_service.dart`:
```dart
static const String baseUrl = 'http://localhost:8000';  // Or your server IP
```

### 6. Install Flutter Dependencies
```bash
flutter pub get
```

### 7. Run Flutter App
```bash
flutter run
```

## ğŸ“± Using the Features

### In Your App
Navigate to the AI Detection screen to:
- âœ… Detect cows/buffaloes in photos
- âœ… Check milking status (lactating/dry)
- âœ… Analyze lameness from walking videos
- âœ… View real-time tracking statistics

### Example Code
See `lib/screens/ai/ai_detection_example_screen.dart` for complete implementation.

## ğŸ”§ Key Files Created

### Backend
```
python_backend/
â”œâ”€â”€ main.py                          # FastAPI app
â”œâ”€â”€ config.py                        # Configuration
â”œâ”€â”€ requirements.txt                 # Dependencies
â”œâ”€â”€ setup.sh                         # Setup script
â”œâ”€â”€ start.sh                         # Start script
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ detection_service.py        # YOLOv8 detection
â”‚   â”œâ”€â”€ tracking_service.py         # ByteTrack
â”‚   â”œâ”€â”€ milking_service.py          # Milking detection
â”‚   â”œâ”€â”€ lameness_service.py         # Lameness detection
â”‚   â””â”€â”€ database_service.py         # Supabase integration
â””â”€â”€ models/
    â””â”€â”€ schemas.py                   # Data models
```

### Flutter
```
lib/
â”œâ”€â”€ services/
â”‚   â””â”€â”€ python_backend_service.dart  # Backend client
â”œâ”€â”€ providers/
â”‚   â””â”€â”€ ai_detection_provider.dart   # State management
â””â”€â”€ screens/
    â””â”€â”€ ai/
        â””â”€â”€ ai_detection_example_screen.dart  # Example UI
```

## ğŸ“ Learn More

- **Complete Guide**: See `BACKEND_INTEGRATION_GUIDE.md`
- **Backend Docs**: See `python_backend/README.md`
- **API Docs**: Visit `http://localhost:8000/docs` when backend is running

## ğŸ”„ Workflow

```
1. User takes photo/video in Flutter app
   â†“
2. Flutter sends to Python backend via HTTP
   â†“
3. Backend runs ML models (YOLOv8, etc.)
   â†“
4. Results saved to Supabase
   â†“
5. Flutter receives and displays results
```

## âš¡ Testing

### Test Backend
```bash
curl http://localhost:8000/health
```

### Test Detection
```bash
curl -X POST -F "file=@test_image.jpg" http://localhost:8000/api/detect
```

### Test from Flutter
1. Run backend
2. Run Flutter app
3. Use camera to test features

## ğŸ“Š What Each Feature Does

### 1. Animal Detection
- **Input**: Photo
- **Output**: List of detected cows/buffaloes with bounding boxes
- **Rejects**: Dogs, cats, goats, chickens, etc.

### 2. Tracking & Counting
- **Input**: Video stream
- **Output**: Unique ID for each animal, count totals
- **Uses**: ByteTrack algorithm

### 3. Milking Status
- **Input**: Photo of animal (side/rear view)
- **Output**: Milking/Dry status with confidence
- **Method**: Udder detection + size analysis

### 4. Lameness Detection
- **Input**: Video of animal walking
- **Output**: Normal/Mild/Moderate/Severe with gait metrics
- **Method**: Pose estimation + ML classifier

## ğŸš€ Next Steps

1. **Train Custom Models**
   - Collect cow/buffalo images
   - Train YOLOv8 with your data
   - Replace default models

2. **Deploy to Production**
   - Use VPS or cloud server
   - Set up nginx reverse proxy
   - Enable HTTPS

3. **Optimize Performance**
   - Enable GPU acceleration
   - Use model quantization
   - Implement caching

## â“ Troubleshooting

**Backend won't start?**
- Check Python version (3.8+)
- Run `./setup.sh` again
- Check `.env` file exists

**Detection not working?**
- Verify backend is running
- Check Flutter app URL matches backend
- Test with `curl` first

**Low accuracy?**
- Train custom models with your cattle
- Adjust confidence threshold
- Improve image quality

## ğŸ“ Support

- See detailed docs in `BACKEND_INTEGRATION_GUIDE.md`
- Check API docs at `http://localhost:8000/docs`
- Review example code in `ai_detection_example_screen.dart`

---

**Created by**: Cattle AI Development Team
**Date**: January 2026
**Version**: 1.0.0
